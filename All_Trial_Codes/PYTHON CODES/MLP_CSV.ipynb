{"cells":[{"cell_type":"markdown","id":"76aef706-1e45-4dcc-b615-583f94e86baf","metadata":{"id":"76aef706-1e45-4dcc-b615-583f94e86baf"},"source":["# MLP_CSV"]},{"cell_type":"code","execution_count":null,"id":"0873814c-2f18-4ed3-970e-cf12e5d0ff69","metadata":{"id":"0873814c-2f18-4ed3-970e-cf12e5d0ff69"},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","\n","# N2 ve Z2 olarak klasörleri güncelle\n","normal_klasoru = r\"C:\\Users\\oztur\\Desktop\\N\"\n","okra_klasoru = r\"C:\\Users\\oztur\\Desktop\\Z\"\n","\n","# Okra ve normal verilerini saklamak için boş liste oluştur\n","okra_verileri = []\n","normal_verileri = []\n","\n","# Okra dosyalarını oku ve verileri okra_verileri listesine ekle\n","for dosya in os.listdir(okra_klasoru):\n","\tif dosya.endswith('.csv'):\n","    \tdosya_yolu = os.path.join(okra_klasoru, dosya)\n","    \tveri = pd.read_csv(dosya_yolu)\n","    \tokra_verileri.append(veri[['Wavelength (nm)', 'Absorbance (AU)']].values.flatten())  # Düzleştirme işlemi\n","\n","# Normal dosyaları oku ve verileri normal_verileri listesine ekle\n","for dosya in os.listdir(normal_klasoru):\n","\tif dosya.endswith('.csv'):\n","    \tdosya_yolu = os.path.join(normal_klasoru, dosya)\n","    \tveri = pd.read_csv(dosya_yolu)\n","    \tnormal_verileri.append(veri[['Wavelength (nm)', 'Absorbance (AU)']].values.flatten())  # Düzleştirme işlemi\n","\n","# Okra ve normal verilerini birleştir\n","okra_etiketleri = [1] * len(okra_verileri)  # Okra için etiketler 1\n","normal_etiketleri = [0] * len(normal_verileri)  # Normal için etiketler 0\n","\n","# Verileri ve etiketleri birleştir\n","X = np.concatenate((okra_verileri, normal_verileri))\n","y = np.concatenate((okra_etiketleri, normal_etiketleri))\n","\n","# Verileri standartlaştırma\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Verileri eğitim ve test setlerine ayır\n","X_egitim, X_test, y_egitim, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Model oluşturma\n","model = MLPClassifier(\n","\thidden_layer_sizes=(100, 50),  # Gizli katmanlar\n","\tactivation='relu',  # Aktivasyon fonksiyonu\n","\tsolver='adam',  # Optimizasyon algoritması\n","\tmax_iter=1000,  # İterasyon sayısı\n","\trandom_state=42\n",")\n","\n","# Modeli eğitme\n","model.fit(X_egitim, y_egitim)\n","\n","# Test seti üzerinde modeli değerlendirme\n","tahminler = model.predict(X_test)\n","dogruluk_skoru = accuracy_score(y_test, tahminler)\n","dogruluk_yuzde = dogruluk_skoru * 100\n","print(\"Model Doğruluğu: {:.2f}%\".format(dogruluk_yuzde))\n"]},{"cell_type":"markdown","source":["# PNG Kodu"],"metadata":{"id":"0YQ8afSMVMcv"},"id":"0YQ8afSMVMcv"},{"cell_type":"code","source":["import os\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import GridSearchCV\n","from skimage.io import imread\n","from skimage.transform import resize\n","from keras.preprocessing.image import load_img, img_to_array\n","from keras.optimizers import Adam\n","\n","from google.colab import drive\n","\n","# Google Drive bağlantısını oluştur\n","drive.mount('/content/gdrive')\n","\n","# Veri yolları\n","okra_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Grafikler/Okralı Grafik Siyah-Beyaz\"\n","normal_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Grafikler/Sağlıklı Grafik Siyah-Beyaz\"\n","\n","# Okra ve normal verilerini saklamak için boş liste oluştur\n","okra_verileri = []\n","normal_verileri = []\n","\n","# Okra dosyalarını oku ve verileri okra_verileri listesine ekle\n","#for dosya in os.listdir(okra_klasoru):\n"," #   if dosya.endswith('.png'):\n","  #      dosya_yolu = os.path.join(okra_klasoru, dosya)\n","   #     veri = imread(dosya_yolu)\n","    #    veri = resize(veri, (256, 256))  # Görüntü boyutunu 256x256 piksel olarak yeniden boyutlandır\n","     #   okra_verileri.append(veri.flatten())  # Düzleştirme işlemi\n","\n","# Normal dosyaları oku ve verileri normal_verileri listesine ekle\n","#for dosya in os.listdir(normal_klasoru):\n"," #   if dosya.endswith('.png'):\n","  #      dosya_yolu = os.path.join(normal_klasoru, dosya)\n","   #     veri = imread(dosya_yolu)\n","    #    veri = resize(veri, (256, 256))  # Görüntü boyutunu 256x256 piksel olarak yeniden boyutlandır\n","     #   normal_verileri.append(veri.flatten())  # Düzleştirme işlemi\n","\n","# Zararlı sınıf için verileri yükleme\n","for dosya_adi in os.listdir(okra_klasoru):\n","    dosya_yolu = os.path.join(okra_klasoru, dosya_adi)\n","    img = load_img(dosya_yolu, target_size=(256, 256))\n","    img = img_to_array(img)\n","    okra_verileri.append(img.flatten())  # Düzleştirme işlemi\n","\n","# Normal sınıf için verileri yükleme\n","for dosya_adi in os.listdir(normal_klasoru):\n","    dosya_yolu = os.path.join(normal_klasoru, dosya_adi)\n","    img = load_img(dosya_yolu, target_size=(256, 256))\n","    img = img_to_array(img)\n","    normal_verileri.append(img.flatten())  # Düzleştirme işlemi\n","\n","\n","# Okra ve normal verilerini birleştir\n","okra_etiketleri = [1] * len(okra_verileri)  # Okra için etiketler 1\n","normal_etiketleri = [0] * len(normal_verileri)  # Normal için etiketler 0\n","\n","# Verileri ve etiketleri birleştir\n","X = np.concatenate((okra_verileri, normal_verileri))\n","y = np.concatenate((okra_etiketleri, normal_etiketleri))\n","\n","# Verileri standartlaştırma\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Verileri eğitim ve test setlerine ayır\n","X_egitim, X_test, y_egitim, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Model oluşturma ve parametreleri belirleme\n","model = MLPClassifier(\n","    hidden_layer_sizes=(100,),  # Gizli katmanların boyutu\n","    activation='relu',          # Aktivasyon fonksiyonu\n","    solver='adam',              # Optimizasyon algoritması\n","    alpha=0.0001,               # L2 düzenleme parametresi\n","    batch_size='auto',          # Mini-batch boyutu, 'auto' otomatik olarak seçilir\n","    learning_rate='constant',   # Öğrenme oranı stratejisi\n","    max_iter=200,               # Maksimum iterasyon sayısı\n","    shuffle=True,               # Her epoch öncesi verilerin karıştırılması\n","    random_state=42             # Rastgelelik için sabit bir değer\n",")\n","\n","# Modeli eğitme\n","model.fit(X_egitim, y_egitim, epochs=20, batch_size=32, validation_split=0.1)\n","\n","# Test seti üzerinde modeli değerlendirme\n","tahminler = model.predict(X_test)\n","dogruluk_skoru = accuracy_score(y_test, tahminler)\n","dogruluk_yuzde = dogruluk_skoru * 100\n","print(\"MLP Model Doğruluğu: {:.2f}%\".format(dogruluk_yuzde))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"id":"tM7B_xvdVOKG","outputId":"0440ce8b-271b-4fda-fa11-ecc9f1b4e2a7","executionInfo":{"status":"error","timestamp":1713970401892,"user_tz":-180,"elapsed":42119,"user":{"displayName":"Ali Baki Türköz","userId":"12429481567888418622"}}},"id":"tM7B_xvdVOKG","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]},{"output_type":"error","ename":"TypeError","evalue":"BaseMultilayerPerceptron.fit() got an unexpected keyword argument 'epochs'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-b2a9aab39a58>\u001b[0m in \u001b[0;36m<cell line: 86>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m# Modeli eğitme\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_egitim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_egitim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# Test seti üzerinde modeli değerlendirme\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: BaseMultilayerPerceptron.fit() got an unexpected keyword argument 'epochs'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"uv90XRkSVs5Z"},"id":"uv90XRkSVs5Z","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}