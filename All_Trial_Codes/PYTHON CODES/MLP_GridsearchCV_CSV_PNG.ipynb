{"cells":[{"cell_type":"markdown","id":"27a408a1-2205-47fa-9e3c-d9e79fa049b7","metadata":{"id":"27a408a1-2205-47fa-9e3c-d9e79fa049b7"},"source":["# MLP+GRİDSEARCHCV_CSV"]},{"cell_type":"code","execution_count":null,"id":"63d6012f-0bba-46ac-ae47-21fc580e2bd9","metadata":{"id":"63d6012f-0bba-46ac-ae47-21fc580e2bd9"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"9cfefc72-6b4f-49ed-844a-8521b91e8f82","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9cfefc72-6b4f-49ed-844a-8521b91e8f82","executionInfo":{"status":"ok","timestamp":1713099910116,"user_tz":-180,"elapsed":857103,"user":{"displayName":"ALİ BAKİ TÜRKÖZ","userId":"13381081740374735745"}},"outputId":"7e9d8f86-2111-4dea-f933-77e4af61fb8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["MLP+GridsearchCV Model Doğruluğu: 91.00%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]}],"source":["import os\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import GridSearchCV\n","from google.colab import drive\n","\n","# Google Drive bağlantısını oluştur\n","drive.mount('/content/gdrive')\n","\n","# Veri yolları\n","okra_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Raisin/Okralı\"\n","normal_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Raisin/Sağlıklı\"\n","\n","# Okra ve normal verilerini saklamak için boş liste oluştur\n","okra_verileri = []\n","normal_verileri = []\n","\n","# Okra dosyalarını oku ve verileri okra_verileri listesine ekle\n","for dosya in os.listdir(okra_klasoru):\n","    if dosya.endswith('_r.csv'):\n","        dosya_yolu = os.path.join(okra_klasoru, dosya)\n","        veri = pd.read_csv(dosya_yolu)\n","        okra_verileri.append(veri[['Wavelength (nm)', 'Reflectance (AU)']].values.flatten())  # Düzleştirme işlemi\n","\n","# Normal dosyaları oku ve verileri normal_verileri listesine ekle\n","for dosya in os.listdir(normal_klasoru):\n","    if dosya.endswith('_r.csv'):\n","        dosya_yolu = os.path.join(normal_klasoru, dosya)\n","        veri = pd.read_csv(dosya_yolu)\n","        normal_verileri.append(veri[['Wavelength (nm)', 'Reflectance (AU)']].values.flatten())  # Düzleştirme işlemi\n","\n","# Okra ve normal verilerini birleştir\n","okra_etiketleri = [1] * len(okra_verileri)  # Okra için etiketler 1\n","normal_etiketleri = [0] * len(normal_verileri)  # Normal için etiketler 0\n","\n","# Verileri ve etiketleri birleştir\n","X = np.concatenate((okra_verileri, normal_verileri))\n","y = np.concatenate((okra_etiketleri, normal_etiketleri))\n","\n","# Verileri standartlaştırma\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Verileri eğitim ve test setlerine ayır\n","X_egitim, X_test, y_egitim, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Model oluşturma\n","model = MLPClassifier(random_state=42)\n","\n","# Hiperparametre aralıklarını tanımlama\n","param_grid = {\n","\t'hidden_layer_sizes': [(100,), (100, 50), (150, 100)],\n","\t'activation': ['relu', 'tanh'],\n","\t'solver': ['adam', 'sgd'],\n","\t'max_iter': [500, 1000, 1500]\n","}\n","\n","# GridSearchCV ile en iyi hiperparametreleri bulma\n","grid_search = GridSearchCV(model, param_grid, cv=3, n_jobs=-1)\n","grid_search.fit(X_egitim, y_egitim)\n","\n","# En iyi modeli seçme\n","model = grid_search.best_estimator_\n","\n","# Modeli eğitme.\n","model.fit(X_egitim, y_egitim)\n","\n","# Test seti üzerinde modeli değerlendirme\n","tahminler = model.predict(X_test)\n","dogruluk_skoru = accuracy_score(y_test, tahminler)\n","dogruluk_yuzde = dogruluk_skoru * 100\n","print(\"MLP+GridsearchCV Model Doğruluğu: {:.2f}%\".format(dogruluk_yuzde))"]},{"cell_type":"code","execution_count":null,"id":"f03ffed8-7562-4812-a6be-752cc5271dd8","metadata":{"id":"f03ffed8-7562-4812-a6be-752cc5271dd8"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# PNG KODU"],"metadata":{"id":"6hAq0bMMnJel"},"id":"6hAq0bMMnJel"},{"cell_type":"code","source":["import os\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import GridSearchCV\n","from skimage.io import imread\n","from skimage.transform import resize\n","from keras.preprocessing.image import load_img, img_to_array\n","\n","from google.colab import drive\n","\n","# Google Drive bağlantısını oluştur\n","drive.mount('/content/gdrive')\n","\n","# Veri yolları\n","okra_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Grafikler/Okralı Grafik Siyah-Beyaz\"\n","normal_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Grafikler/Sağlıklı Grafik Siyah-Beyaz\"\n","\n","# Okra ve normal verilerini saklamak için boş liste oluştur\n","okra_verileri = []\n","normal_verileri = []\n","\n","# Okra dosyalarını oku ve verileri okra_verileri listesine ekle\n","#for dosya in os.listdir(okra_klasoru):\n"," #   if dosya.endswith('.png'):\n","  #      dosya_yolu = os.path.join(okra_klasoru, dosya)\n","   #     veri = imread(dosya_yolu)\n","    #    veri = resize(veri, (256, 256))  # Görüntü boyutunu 256x256 piksel olarak yeniden boyutlandır\n","     #   okra_verileri.append(veri.flatten())  # Düzleştirme işlemi\n","\n","# Normal dosyaları oku ve verileri normal_verileri listesine ekle\n","#for dosya in os.listdir(normal_klasoru):\n"," #   if dosya.endswith('.png'):\n","  #      dosya_yolu = os.path.join(normal_klasoru, dosya)\n","   #     veri = imread(dosya_yolu)\n","    #    veri = resize(veri, (256, 256))  # Görüntü boyutunu 256x256 piksel olarak yeniden boyutlandır\n","     #   normal_verileri.append(veri.flatten())  # Düzleştirme işlemi\n","\n","# Zararlı sınıf için verileri yükleme\n","for dosya_adi in os.listdir(okra_klasoru):\n","    dosya_yolu = os.path.join(okra_klasoru, dosya_adi)\n","    img = load_img(dosya_yolu, target_size=(256, 256))\n","    img = img_to_array(img)\n","    okra_verileri.append(img.flatten())  # Düzleştirme işlemi\n","\n","# Normal sınıf için verileri yükleme\n","for dosya_adi in os.listdir(normal_klasoru):\n","    dosya_yolu = os.path.join(normal_klasoru, dosya_adi)\n","    img = load_img(dosya_yolu, target_size=(256, 256))\n","    img = img_to_array(img)\n","    normal_verileri.append(img.flatten())  # Düzleştirme işlemi\n","\n","\n","# Okra ve normal verilerini birleştir\n","okra_etiketleri = [1] * len(okra_verileri)  # Okra için etiketler 1\n","normal_etiketleri = [0] * len(normal_verileri)  # Normal için etiketler 0\n","\n","# Verileri ve etiketleri birleştir\n","X = np.concatenate((okra_verileri, normal_verileri))\n","y = np.concatenate((okra_etiketleri, normal_etiketleri))\n","\n","# Verileri standartlaştırma\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Verileri eğitim ve test setlerine ayır\n","X_egitim, X_test, y_egitim, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Model oluşturma\n","model = MLPClassifier(random_state=42)\n","\n","# Hiperparametre aralıklarını tanımlama\n","param_grid = {\n","\t'hidden_layer_sizes': [(100,), (100, 50), (150, 100)],\n","\t'activation': ['relu', 'tanh', 'sigmoid', 'softmax'],\n","\t'solver': ['adam', 'sgd'],\n","\t'max_iter': [500, 1000, 1500]\n","}\n","\n","# GridSearchCV ile en iyi hiperparametreleri bulma\n","grid_search = GridSearchCV(model, param_grid, cv=3, n_jobs=1)\n","grid_search.fit(X_egitim, y_egitim)\n","\n","# En iyi modeli seçme\n","model = grid_search.best_estimator_\n","\n","# Modeli eğitme.\n","model.fit(X_egitim, y_egitim)\n","\n","# Test seti üzerinde modeli değerlendirme\n","tahminler = model.predict(X_test)\n","dogruluk_skoru = accuracy_score(y_test, tahminler)\n","dogruluk_yuzde = dogruluk_skoru * 100\n","print(\"MLP+GridsearchCV Model Doğruluğu: {:.2f}%\".format(dogruluk_yuzde))\n"],"metadata":{"id":"UAnG-39SnL8z","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1dfa9a47-b32d-4cff-f53c-c4429b04b9fa"},"id":"UAnG-39SnL8z","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Gc36BPSfnyIz"},"id":"Gc36BPSfnyIz","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}