{"cells":[{"cell_type":"markdown","metadata":{"id":"zoSHqiqRZVTF"},"source":["# Data Analysis"],"id":"zoSHqiqRZVTF"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59060,"status":"ok","timestamp":1714469051105,"user":{"displayName":"TFX","userId":"15890455650698833197"},"user_tz":-180},"id":"pLgMYMM8RZkS","outputId":"97d29f22-f4f1-4927-d9db-38c9fe8112ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Google Drive API\n","from google.colab import drive\n","\n","# Drive bağlantısını oluştur\n","drive.mount('/content/gdrive')\n"],"id":"pLgMYMM8RZkS"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"elapsed":5602,"status":"error","timestamp":1711103058561,"user":{"displayName":"ALİ BAKİ TÜRKÖZ","userId":"13381081740374735745"},"user_tz":-180},"id":"E-PNt7dxVjky","outputId":"274d64ad-5b7b-4183-bf05-207dffb334cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]},{"ename":"UnicodeDecodeError","evalue":"'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-d41cdaef053b>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdosya\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mokra_klasoru\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdosya_yolu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mokra_klasoru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdosya\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mveri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdosya_yolu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mokra_veriler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mokra_veriler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mveri\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_dtype_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n","\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte"]}],"source":["import os\n","import pandas as pd\n","\n","# Google Drive API\n","from google.colab import drive\n","\n","# Drive bağlantısını oluştur\n","drive.mount('/content/gdrive')\n","\n","# Veri klasörlerini belirt\n","okra_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Grafikler/160Data_40_228_BlackBox_Factory_Graphs/Okralı\"\n","normal_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Grafikler/160Data_40_228_BlackBox_Factory_Graphs/Normal\"\n","\n","# Okra verilerini depolamak için boş bir DataFrame oluştur\n","okra_veriler = pd.DataFrame()\n","\n","# Okra klasöründeki .csv dosyalarını oku\n","for dosya in os.listdir(okra_klasoru):\n","    dosya_yolu = os.path.join(okra_klasoru, dosya)\n","    veri = pd.read_csv(dosya_yolu)\n","    okra_veriler = pd.concat([okra_veriler, veri], ignore_index=True)\n","\n","# Normal verilerini depolamak için boş bir DataFrame oluştur\n","normal_veriler = pd.DataFrame()\n","\n","# Normal klasöründeki .csv dosyalarını oku\n","for dosya in os.listdir(normal_klasoru):\n","    dosya_yolu = os.path.join(normal_klasoru, dosya)\n","    veri = pd.read_csv(dosya_yolu)\n","    normal_veriler = pd.concat([normal_veriler, veri], ignore_index=True)\n","\n","# Okra verilerinin istatistiksel özetini görüntüle\n","print(\"Okra Verilerinin İstatistiksel Özeti:\")\n","print(okra_veriler.describe())\n","\n","# Normal verilerinin istatistiksel özetini görüntüle\n","print(\"\\nNormal Verilerinin İstatistiksel Özeti:\")\n","print(normal_veriler.describe())\n","\n"],"id":"E-PNt7dxVjky"},{"cell_type":"markdown","metadata":{"id":"0BYhuUoJkdg1"},"source":["# **Saf Haliyle İşlemsiz Decision Tree, Random Forest, KNN, SVM**"],"id":"0BYhuUoJkdg1"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3048,"status":"ok","timestamp":1711050903610,"user":{"displayName":"ALİ BAKİ TÜRKÖZ","userId":"13381081740374735745"},"user_tz":-180},"id":"X-Ayen8wjoPh","outputId":"a2cc2287-bc7c-4ee8-b449-861e57c52a4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["# Google Drive API\n","from google.colab import drive\n","\n","# Drive bağlantısını oluştur\n","drive.mount('/content/gdrive')"],"id":"X-Ayen8wjoPh"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1c26334a-b3a8-4acc-977e-4ab5901d20d3","outputId":"e13f0211-df90-497d-ba3d-71d980df3925"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Decision Tree Doğruluk Oranı: 0.5804\n","Random Forest Doğruluk Oranı: 0.5821\n","K-Nearest Neighbors Doğruluk Oranı: 0.6121\n"]}],"source":["import os\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","\n","# Google Drive API\n","from google.colab import drive\n","\n","# Drive bağlantısını oluştur\n","drive.mount('/content/gdrive')\n","\n","# Veri klasörlerini belirt\n","okra_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Raisin/Okralı/Absorbance\"\n","normal_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Raisin/Sağlıklı/Absorbance\"\n","\n","# Verileri depolamak için boş bir DataFrame oluştur\n","tum_veriler = pd.DataFrame()\n","\n","\n","# .csv dosyalarını oku ve NaN değerleri ortalama ile doldur\n","for klasor, label in [(okra_klasoru, 'Okra'), (normal_klasoru, 'Normal')]:\n","    dosyalar = os.listdir(klasor)\n","\n","    for dosya in dosyalar:\n","        dosya_yolu = os.path.join(klasor, dosya)\n","        veri = pd.read_csv(dosya_yolu)\n","   # NaN değerleri ortalama ile doldur\n","        #veri = veri.fillna(veri.mean())\n","   # NaN değerleri bir önceki ve bir sonraki değerin ortalaması ile doldur\n","        #veri = veri.fillna((veri.shift(1) + veri.shift(-1)) / 2)\n","        veri['Label'] = label  # Etiket sütunu ekle\n","        tum_veriler = pd.concat([tum_veriler, veri], ignore_index=True)\n","\n","# Verileri sınıflandırma için hazırla\n","X = tum_veriler[['Wavelength (nm)', 'Absorbance (AU)']]\n","y = tum_veriler['Label']\n","\n","# Veri normalizasyonu\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Verileri eğitim ve test setlerine ayır\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n","\n","# Modelleri oluştur, eğit ve doğruluk oranlarını ekrana bastır\n","models = {\n","    'Decision Tree': DecisionTreeClassifier(),\n","    'Random Forest': RandomForestClassifier(),\n","    'K-Nearest Neighbors': KNeighborsClassifier(),\n","    'Support Vector Machine': SVC(kernel='linear', C=1)\n","}\n","\n","\n","\n","for model_name, model in models.items():\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    dogruluk_orani = accuracy_score(y_test, y_pred)\n","    print(f\"{model_name} Doğruluk Oranı: {dogruluk_orani:.4f}\")\n"],"id":"1c26334a-b3a8-4acc-977e-4ab5901d20d3"},{"cell_type":"markdown","metadata":{"id":"CQ4rrsB1kRuf"},"source":["# **`Bir Önceki ve Bir Sonraki Ortalama İle Doldur`**"],"id":"CQ4rrsB1kRuf"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460},"executionInfo":{"elapsed":4139,"status":"error","timestamp":1710507250265,"user":{"displayName":"ALİ BAKİ TÜRKÖZ","userId":"13381081740374735745"},"user_tz":-180},"id":"ad19f551-2439-4cfe-bdb7-a5371cbdf899","outputId":"542d25e7-3f54-4d33-9fb9-521878759836"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]},{"ename":"ValueError","evalue":"Input X contains NaN.\nDecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-c48b0bf8a670>\u001b[0m in \u001b[0;36m<cell line: 66>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Modelleri eğit ve doğruluk oranlarını ekrana bastır\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mdogruluk_orani\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcheck_X_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                     \u001b[0mcheck_X_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nDecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"]}],"source":["import os\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","import numpy as np\n","\n","# Google Drive API\n","from google.colab import drive\n","\n","# Drive bağlantısını oluştur\n","drive.mount('/content/gdrive')\n","\n","# Veri klasörlerini belirt\n","okra_klasoru = '/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Raisin/Raisins_20Data/Number_of_scan_20_resouliton_352/Okralı/White_Background/Factory_Reference/Absorbance'\n","normal_klasoru = '/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Raisin/Raisins_20Data/Number_of_scan_20_resouliton_352/Normal/White_Background/Factory_Reference/Absorbance'\n","\n","# Verileri depolamak için boş bir DataFrame oluştur\n","tum_veriler = pd.DataFrame()\n","\n","# .csv dosyalarını oku ve NaN değerleri bir önceki ve sonraki ile doldur\n","def doldur_ortalama(veri):\n","    for i in range(len(veri)):\n","        if np.isnan(veri.iloc[i, 0]):\n","            if i == 0:\n","                veri.iloc[i, 0] = veri.iloc[i+1, 0]\n","            elif i == len(veri)-1:\n","                veri.iloc[i, 0] = veri.iloc[i-1, 0]\n","            else:\n","                veri.iloc[i, 0] = (veri.iloc[i-1, 0] + veri.iloc[i+1, 0]) / 2\n","    return veri\n","\n","for klasor, label in [(okra_klasoru, 'Okra'), (normal_klasoru, 'Normal')]:\n","    dosyalar = os.listdir(klasor)\n","\n","    for dosya in dosyalar:\n","        dosya_yolu = os.path.join(klasor, dosya)\n","        veri = pd.read_csv(dosya_yolu)\n","        veri = doldur_ortalama(veri) # NaN değerlerini bir önceki ve sonraki ile doldur\n","        veri['Label'] = label\n","        tum_veriler = pd.concat([tum_veriler, veri], ignore_index=True)\n","\n","# Verileri sınıflandırma için hazırla\n","X = tum_veriler[['Wavelength (nm)', 'Absorbance (AU)']]\n","y = tum_veriler['Label']\n","\n","# Veri normalizasyonu\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Verileri eğitim ve test setlerine ayır\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n","\n","# Modelleri oluştur\n","models = {\n","    'Decision Tree': DecisionTreeClassifier(),\n","    'Random Forest': RandomForestClassifier(),\n","    'K-Nearest Neighbors': KNeighborsClassifier(),\n","    'Support Vector Machine': SVC(kernel='linear', C=1)\n","}\n","# Modelleri eğit ve doğruluk oranlarını ekrana bastır\n","for model_name, model in models.items():\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    dogruluk_orani = accuracy_score(y_test, y_pred)\n","    print(f\"{model_name} Doğruluk Oranı: {dogruluk_orani:.4f}\")\n","\n"],"id":"ad19f551-2439-4cfe-bdb7-a5371cbdf899"},{"cell_type":"markdown","metadata":{"id":"uXPxt2Hd47j6"},"source":["# Komplex SVM Metodları\n","\n","\n","---\n","\n"],"id":"uXPxt2Hd47j6"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":467158,"status":"ok","timestamp":1711054029993,"user":{"displayName":"ALİ BAKİ TÜRKÖZ","userId":"13381081740374735745"},"user_tz":-180},"id":"1S-UggrH8xeU","outputId":"5f7733bc-cfdf-4e93-89e0-6f93cfaefb90"},"outputs":[{"name":"stdout","output_type":"stream","text":["Decision Tree Doğruluk Oranı: 0.6080\n","Random Forest Doğruluk Oranı: 0.6142\n","K-Nearest Neighbors Doğruluk Oranı: 0.6439\n","Kompleks Support Vector Machine Doğruluk Oranı: 0.6714\n"]}],"source":["import os\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# Google Drive API\n","from google.colab import drive\n","\n","# Veri klasörlerini belirt\n","okra_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Raisin/Okralı/Absorbance\"\n","normal_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Raisin/Sağlıklı/Absorbance\"\n","\n","# Verileri depolamak için boş bir DataFrame oluştur\n","tum_veriler = pd.DataFrame()\n","\n","# .csv dosyalarını oku ve NaN değerleri ortalama ile doldur\n","for klasor, label in [(okra_klasoru, 'Okra'), (normal_klasoru, 'Normal')]:\n","    dosyalar = os.listdir(klasor)\n","\n","    for dosya in dosyalar:\n","        dosya_yolu = os.path.join(klasor, dosya)\n","        veri = pd.read_csv(dosya_yolu)\n","       # veri = veri.fillna(veri.mean())  # NaN değerleri ortalama ile doldur\n","\n","        #veri = veri.fillna((veri.shift(1) + veri.shift(-1)) / 2) # NaN değerleri bir önceki ve bir sonraki değerin ortalaması ile doldur\n","\n","        veri['Label'] = label  # Etiket sütunu ekle\n","        tum_veriler = pd.concat([tum_veriler, veri], ignore_index=True)\n","\n","# Verileri sınıflandırma için hazırla\n","X = tum_veriler[['Wavelength (nm)', 'Absorbance (AU)']]\n","y = tum_veriler['Label']\n","\n","# Aykırı değerleri sınırlandırma (alt sınır: 1. persentil, üst sınır: 99. persentil)\n","alt_sinir = X.quantile(0.01)\n","ust_sinir = X.quantile(0.99)\n","X = X.clip(lower=alt_sinir, upper=ust_sinir, axis=1)  # Apply clip function to each column (axis=1)\n","\n","# Veri normalizasyonu\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Verileri eğitim ve test setlerine ayır\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n","\n","# Modelleri oluştur\n","models = {\n","    'Decision Tree': DecisionTreeClassifier(),\n","    'Random Forest': RandomForestClassifier(),\n","    'K-Nearest Neighbors': KNeighborsClassifier(),\n","    'Kompleks Support Vector Machine': SVC(kernel='rbf', C=13, gamma='scale')  # RBF kernel ve C=10\n","}\n","\n","# Modelleri eğit ve doğruluk oranlarını ekrana bastır\n","for model_name, model in models.items():\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    dogruluk_orani = accuracy_score(y_test, y_pred)\n","    print(f\"{model_name} Doğruluk Oranı: {dogruluk_orani:.4f}\")\n"],"id":"1S-UggrH8xeU"},{"cell_type":"markdown","metadata":{"id":"W2uWJaIWMUTO"},"source":["# Veri Artırma Sonrası"],"id":"W2uWJaIWMUTO"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1690322,"status":"ok","timestamp":1711055804691,"user":{"displayName":"ALİ BAKİ TÜRKÖZ","userId":"13381081740374735745"},"user_tz":-180},"id":"Xe697xlkMY61","outputId":"b3bf41ae-904b-4dee-fd6b-cae3ca12ea22"},"outputs":[{"name":"stdout","output_type":"stream","text":["Decision Tree Doğruluk Oranı: 0.6097\n","Random Forest Doğruluk Oranı: 0.6038\n","K-Nearest Neighbors Doğruluk Oranı: 0.6523\n","Kompleks Support Vector Machine Doğruluk Oranı: 0.6714\n"]}],"source":["import os\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.utils import resample\n","\n","# Google Drive API\n","from google.colab import drive\n","\n","# Veri klasörlerini belirt\n","okra_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Raisin/160Data_20_352_White_Factory_CSV/Okralı/Reflectance\"\n","normal_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Raisin/160Data_20_352_White_Factory_CSV/Normal/Reflectance\"\n","\n","# Verileri depolamak için boş bir DataFrame oluştur\n","tum_veriler = pd.DataFrame()\n","\n","# .csv dosyalarını oku ve NaN değerleri ortalama ile doldur\n","for klasor, label in [(okra_klasoru, 'Okra'), (normal_klasoru, 'Normal')]:\n","    dosyalar = os.listdir(klasor)\n","\n","    for dosya in dosyalar:\n","        dosya_yolu = os.path.join(klasor, dosya)\n","        veri = pd.read_csv(dosya_yolu, encoding='latin-1')\n","       # veri = veri.fillna(veri.mean())  # NaN değerleri ortalama ile doldur\n","       #veri = veri.fillna((veri.shift(1) + veri.shift(-1)) / 2) # NaN değerleri bir önceki ve bir sonraki değerin ortalaması ile doldur\n","        veri['Label'] = label  # Etiket sütunu ekle\n","        tum_veriler = pd.concat([tum_veriler, veri], ignore_index=True)\n","\n","# Verileri sınıflandırma için hazırla\n","X = tum_veriler[['Wavelength (nm)', 'Reflectance (AU)']]\n","y = tum_veriler['Label']\n","\n","# Aykırı değerleri sınırlandırma (alt sınır: 1. persentil, üst sınır: 99. persentil)\n","alt_sinir = X.quantile(0.01)\n","ust_sinir = X.quantile(0.99)\n","X = X.clip(lower=alt_sinir, upper=ust_sinir, axis=1)  # Apply clip function to each column (axis=1)\n","\n","# Veri normalizasyonu\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Verileri eğitim ve test setlerine ayır\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n","\n","# Veri artırma fonksiyonu tanımla\n","def augment_data(X, y, n_samples):\n","    augmented_X = []\n","    augmented_y = []\n","\n","    # Her sınıf için veri artırma yap\n","    for label in set(y):\n","        # Sınıfa ait örnekleri seç\n","        X_class = X[y == label]\n","        y_class = y[y == label]\n","\n","        # Veri sayısını kontrol et\n","        n_samples_class = len(X_class)\n","\n","        # Eğer sınıfın örneği n_samples'dan azsa, artır\n","        if n_samples_class < n_samples:\n","            n_to_generate = n_samples - n_samples_class\n","            augmented_X_class, augmented_y_class = resample(X_class, y_class, n_samples=n_to_generate, random_state=42)\n","            augmented_X.extend(augmented_X_class)\n","            augmented_y.extend(augmented_y_class)\n","        else:\n","            augmented_X.extend(X_class)\n","            augmented_y.extend(y_class)\n","\n","    # Artırılmış verileri asıl veriyle birleştir\n","    X_augmented = np.vstack((X, np.array(augmented_X)))\n","    y_augmented = np.hstack((y, np.array(augmented_y)))\n","\n","    return X_augmented, y_augmented\n","\n","# Veri artırma fonksiyonunu kullanarak eğitim verisini artır\n","X_train_augmented, y_train_augmented = augment_data(X_train, y_train, n_samples=1000)\n","\n","# Modelleri oluştur\n","models = {\n","    'Decision Tree': DecisionTreeClassifier(),\n","    'Random Forest': RandomForestClassifier(),\n"," #   'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=8),\n","    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=13, weights='uniform', algorithm='auto', leaf_size=30,\n","                                                p=4, metric='minkowski', metric_params=None, n_jobs=None),\n","    'Kompleks Support Vector Machine': SVC(kernel='rbf', C=13, gamma='scale')  # RBF kernel ve C=10\n","}\n","\n","# Artırılmış verilerle modeli tekrar eğit\n","for model_name, model in models.items():\n","    model.fit(X_train_augmented, y_train_augmented)\n","    y_pred = model.predict(X_test)\n","    dogruluk_orani = accuracy_score(y_test, y_pred)\n","    print(f\"{model_name} Doğruluk Oranı: {dogruluk_orani:.4f}\")\n"],"id":"Xe697xlkMY61"},{"cell_type":"markdown","metadata":{"id":"rBFq1Y_DFLb1"},"source":["# FEATURE EXTRACTİON VE DATA AUGMENTATİON STEPLERİ EKLENMİŞ KOD"],"id":"rBFq1Y_DFLb1"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288085,"status":"ok","timestamp":1714469529054,"user":{"displayName":"TFX","userId":"15890455650698833197"},"user_tz":-180},"id":"tAj1cmRi_0JB","outputId":"0fa1c800-ebf7-454e-f261-f1fe718073c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","Decision Tree (Orijinal) Doğruluk Oranı: 0.5837\n","Decision Tree (PCA) Doğruluk Oranı: 0.5772\n","Decision Tree (Feature Selection) Doğruluk Oranı: 0.5823\n","Decision Tree (SMOTE) Doğruluk Oranı: 0.5830\n","Random Forest (Orijinal) Doğruluk Oranı: 0.6328\n","Random Forest (PCA) Doğruluk Oranı: 0.6325\n","Random Forest (Feature Selection) Doğruluk Oranı: 0.6324\n","Random Forest (SMOTE) Doğruluk Oranı: 0.6315\n","K-Nearest Neighbors (Orijinal) Doğruluk Oranı: 0.6194\n","K-Nearest Neighbors (PCA) Doğruluk Oranı: 0.6194\n","K-Nearest Neighbors (Feature Selection) Doğruluk Oranı: 0.6194\n","K-Nearest Neighbors (SMOTE) Doğruluk Oranı: 0.6194\n"]}],"source":["import os\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.feature_selection import SelectKBest, chi2\n","from imblearn.over_sampling import SMOTE\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# Google Drive API\n","from google.colab import drive\n","# Drive bağlantısını oluştur\n","drive.mount('/content/gdrive')\n","\n","# Veri klasörlerini belirt\n","normal_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Raisin/Sağlıklı/Absorbance\"\n","okra_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Raisin/Okralı/Absorbance\"\n","\n","# Verileri depolamak için boş bir DataFrame oluştur\n","tum_veriler = pd.DataFrame()\n","\n","# .csv dosyalarını oku ve NaN değerleri ortalama ile doldur\n","for klasor, label in [(okra_klasoru, 'Okra'), (normal_klasoru, 'Normal')]:\n","    dosyalar = os.listdir(klasor)\n","\n","    for dosya in dosyalar:\n","        dosya_yolu = os.path.join(klasor, dosya)\n","        veri = pd.read_csv(dosya_yolu)\n","       # veri = veri.fillna(veri.mean())  # NaN değerleri ortalama ile doldur\n","      # veri = veri.fillna((veri.shift(1) + veri.shift(-1)) / 2) # NaN değerleri bir önceki ve bir sonraki değerin ortalaması ile doldur\n","        veri['Label'] = label  # Etiket sütunu ekle\n","        tum_veriler = pd.concat([tum_veriler, veri], ignore_index=True)\n","\n","# Verileri sınıflandırma için hazırla\n","X = tum_veriler[['Wavelength (nm)', 'Absorbance (AU)']]\n","y = tum_veriler['Label']\n","\n","# ## Feature Extraction Teknikleri\n","\n","# ### 1. Principal Component Analysis (PCA)\n","# 2 bileşene indirge\n","pca = PCA(n_components=2)\n","X_pca = pca.fit_transform(X)\n","\n","# ### 2. Feature Selection\n","# En iyi 2 özelliği seç\n","selector = SelectKBest(chi2, k=2)\n","X_selected = selector.fit_transform(X, y)\n","\n","# ## Data Augmentation Teknikleri\n","\n","# ### 1. SMOTE (Synthetic Minority Over-sampling Technique)\n","# Azınlık sınıfı (Okra) için sentetik örnekler oluştur\n","smote = SMOTE(random_state=50)\n","X_augmented, y_augmented = smote.fit_resample(X, y)\n","\n","# ## Modelleri Oluşturma ve Doğruluk Oranlarını Karşılaştırma\n","\n","models = {\n","   # 'Decision Tree': DecisionTreeClassifier(),\n","    'Decision Tree': DecisionTreeClassifier(criterion='gini', max_depth=None,\n","                                    min_samples_split=3, min_samples_leaf=2,\n","                                    max_features=None),\n","   # 'Random Forest': RandomForestClassifier(),\n","    'Random Forest': RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None,\n","                                     min_samples_split=6, min_samples_leaf=5),\n","   # 'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=8),\n","    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=8, weights='uniform', algorithm='auto', leaf_size=30, p=4,\n","                                                metric='minkowski', metric_params=None, n_jobs=None),\n","   # 'Kompleks Support Vector Machine': SVC(kernel='rbf', C=13, gamma='scale')  # RBF kernel ve C=10\n","}\n","\n","# Farklı veri işleme kombinasyonları için doğruluk oranlarını hesapla\n","for model_name, model in models.items():\n","    for data_type, X_processed in [('Orijinal', X), ('PCA', X_pca), ('Feature Selection', X_selected), ('SMOTE', X_augmented)]:\n","        X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","        dogruluk_orani = accuracy_score(y_test, y_pred)\n","        print(f\"{model_name} ({data_type}) Doğruluk Oranı: {dogruluk_orani:.4f}\")\n"],"id":"tAj1cmRi_0JB"},{"cell_type":"code","execution_count":null,"metadata":{"id":"bwFz5ubeufp2"},"outputs":[],"source":[],"id":"bwFz5ubeufp2"},{"cell_type":"markdown","metadata":{"id":"kq8MWAt5ajHo"},"source":["# (HATALI DATALARA ÖZEL YAPILANDIRILDI) ÜSTTEKİ KODUN AYNISI SADECE HATALI DATALAR ÇIKARTILARAK HATASIZ ÇALIŞTIRILMIŞTIR"],"id":"kq8MWAt5ajHo"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":370},"executionInfo":{"elapsed":589,"status":"error","timestamp":1710566769051,"user":{"displayName":"ALİ BAKİ TÜRKÖZ","userId":"13381081740374735745"},"user_tz":-180},"id":"Od9D64AgaUp1","outputId":"d62f78fc-a60b-45cc-c8f0-b3267ea3987d"},"outputs":[{"ename":"ValueError","evalue":"Input X must be non-negative.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-61-e47fd3381f5c>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# En iyi 2 özelliği seç\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mX_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# ## Data Augmentation Teknikleri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mscore_func_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_func_ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_univariate_selection.py\u001b[0m in \u001b[0;36mchi2\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input X must be non-negative.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;31m# Use a sparse representation for Y by default to reduce memory usage when\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input X must be non-negative."]}],"source":["import os\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.feature_selection import SelectKBest, chi2\n","from imblearn.over_sampling import SMOTE\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# Veri klasörlerini belirt\n","okra_klasoru = '/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Raisin/Raisins_20Data/Number_of_scan_20_resouliton_352/Okralı/White_Background/Factory_Reference/Absorbance'\n","normal_klasoru = '/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Raisin/Raisins_20Data/Number_of_scan_20_resouliton_352/Normal/White_Background/Factory_Reference/Absorbance'\n","\n","# Verileri depolamak için boş bir DataFrame oluştur\n","tum_veriler = pd.DataFrame()\n","\n","# .csv dosyalarını oku ve NaN değerleri ortalama ile doldur\n","for klasor, label in [(okra_klasoru, 'Okra'), (normal_klasoru, 'Normal')]:\n","    dosyalar = os.listdir(klasor)\n","\n","    for dosya in dosyalar:\n","        dosya_yolu = os.path.join(klasor, dosya)\n","        veri = pd.read_csv(dosya_yolu)\n","        veri = veri.fillna(veri.mean())  # NaN değerleri ortalama ile doldur\n","        veri['Label'] = label  # Etiket sütunu ekle\n","        tum_veriler = pd.concat([tum_veriler, veri], ignore_index=True)\n","\n","# Verileri sınıflandırma için hazırla\n","X = tum_veriler[['Wavelength (nm)', 'Absorbance (AU)']]\n","y = tum_veriler['Label']\n","\n","# ## Feature Extraction Teknikleri\n","\n","# ### 1. Principal Component Analysis (PCA)\n","# 2 bileşene indirge\n","pca = PCA(n_components=1)\n","X_pca = pca.fit_transform(X)\n","\n","# ### 2. Feature Selection\n","# En iyi 2 özelliği seç\n","selector = SelectKBest(chi2, k=2)\n","X_selected = selector.fit_transform(X, y)\n","\n","# ## Data Augmentation Teknikleri\n","\n","# ### 1. SMOTE (Synthetic Minority Over-sampling Technique)\n","# Azınlık sınıfı (Okra) için sentetik örnekler oluştur\n","smote = SMOTE(random_state=50)\n","X_augmented, y_augmented = smote.fit_resample(X, y)\n","\n","# ## Modelleri Oluşturma ve Doğruluk Oranlarını Karşılaştırma\n","\n","models = {\n","   'Decision Tree': DecisionTreeClassifier(criterion='gini', max_depth=None,\n","                                    min_samples_split=3, min_samples_leaf=2,\n","                                    max_features=None),\n","   'Random Forest': RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None,\n","                                     min_samples_split=6, min_samples_leaf=5),\n","   'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=8, weights='uniform', algorithm='auto', leaf_size=30, p=4,\n","                                                metric='minkowski', metric_params=None, n_jobs=None),\n","    'Kompleks Support Vector Machine': SVC(kernel='sigmoid', C=10, gamma='scale')  # RBF kernel ve C=10\n","}\n","\n","# Farklı veri işleme kombinasyonları için doğruluk oranlarını hesapla\n","for model_name, model in models.items():\n","    for data_type, X_processed in [('Orijinal', X), ('PCA', X_pca), ('Feature Selection', X_selected), ('SMOTE', X_augmented)]:\n","        if data_type == 'SMOTE':\n","            X_train, X_test, y_train, y_test = train_test_split(X_processed, y_augmented, test_size=0.2, random_state=42)\n","        else:\n","            X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","        dogruluk_orani = accuracy_score(y_test, y_pred)\n","        print(f\"{model_name} ({data_type}) Doğruluk Oranı: {dogruluk_orani:.4f}\")\n"],"id":"Od9D64AgaUp1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"IfJoi4yBuKyN"},"outputs":[],"source":[],"id":"IfJoi4yBuKyN"},{"cell_type":"markdown","metadata":{"id":"gYNMpGzHVNi-"},"source":["# (HATALI DATALARA ÖZEL YAPILANDIRILDI) ÜSTTEKİNE EK OLARAK NEGATİF İNPUTLARI 0'A EŞİTLEYİP EĞİTİM YAPAN KOD (FEATURE EXTRACTİON AND DATA AUG EKLENMİŞ HALİ)"],"id":"gYNMpGzHVNi-"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5935464,"status":"ok","timestamp":1713770409634,"user":{"displayName":"ALİ BAKİ TÜRKÖZ","userId":"13381081740374735745"},"user_tz":-180},"id":"IWh8KxKSVb5-","outputId":"b4887eb4-2a34-4f39-b0e1-f6e9b8eb10af"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","Decision Tree (Orijinal) Doğruluk Oranı: 0.5829\n","Decision Tree (PCA) Doğruluk Oranı: 0.6288\n","Decision Tree (Feature Selection) Doğruluk Oranı: 0.5832\n","Decision Tree (SMOTE) Doğruluk Oranı: 0.5829\n","Random Forest (Orijinal) Doğruluk Oranı: 0.6341\n","Random Forest (PCA) Doğruluk Oranı: 0.6359\n","Random Forest (Feature Selection) Doğruluk Oranı: 0.6340\n","Random Forest (SMOTE) Doğruluk Oranı: 0.6356\n","K-Nearest Neighbors (Orijinal) Doğruluk Oranı: 0.6345\n","K-Nearest Neighbors (PCA) Doğruluk Oranı: 0.6343\n","K-Nearest Neighbors (Feature Selection) Doğruluk Oranı: 0.6345\n","K-Nearest Neighbors (SMOTE) Doğruluk Oranı: 0.6345\n","Kompleks Support Vector Machine (Orijinal) Doğruluk Oranı: 0.4976\n","Kompleks Support Vector Machine (PCA) Doğruluk Oranı: 0.4998\n","Kompleks Support Vector Machine (Feature Selection) Doğruluk Oranı: 0.4976\n","Kompleks Support Vector Machine (SMOTE) Doğruluk Oranı: 0.4976\n"]}],"source":["import os\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.feature_selection import SelectKBest, chi2\n","from imblearn.over_sampling import SMOTE\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# Google Drive API\n","from google.colab import drive\n","# Drive bağlantısını oluştur\n","drive.mount('/content/gdrive')\n","\n","# Veri klasörlerini belirt\n","okra_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Raisin/Okralı/Absorbance\"\n","normal_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Raisin/Sağlıklı/Absorbance\"\n","\n","# Verileri depolamak için boş bir DataFrame oluştur\n","tum_veriler = pd.DataFrame()\n","\n","# .csv dosyalarını oku ve NaN değerleri ortalama ile doldur\n","for klasor, label in [(okra_klasoru, 'Okra'), (normal_klasoru, 'Normal')]:\n","    dosyalar = os.listdir(klasor)\n","\n","    for dosya in dosyalar:\n","        dosya_yolu = os.path.join(klasor, dosya)\n","        veri = pd.read_csv(dosya_yolu)\n","      #  veri = veri.fillna(veri.mean())  # NaN değerleri ortalama ile doldur\n","      # veri = veri.fillna((veri.shift(1) + veri.shift(-1)) / 2) # NaN değerleri bir önceki ve bir sonraki değerin ortalaması ile doldur\n","        veri['Label'] = label  # Etiket sütunu ekle\n","        tum_veriler = pd.concat([tum_veriler, veri], ignore_index=True)\n","\n","# Verileri sınıflandırma için hazırla\n","X = tum_veriler[['Wavelength (nm)', 'Absorbance (AU)']]\n","y = tum_veriler['Label']\n","\n","# Negatif değerleri 0'a eşitleme\n","X_non_negative = X.copy()\n","X_non_negative[X_non_negative < 0] = 0\n","\n","# ## Feature Extraction Teknikleri\n","\n","# ### 1. Principal Component Analysis (PCA)\n","# 2 bileşene indirge\n","pca = PCA(n_components=1)\n","X_pca = pca.fit_transform(X_non_negative)\n","\n","# ### 2. Feature Selection\n","# En iyi 2 özelliği seç\n","selector = SelectKBest(chi2, k=2)\n","X_selected = selector.fit_transform(X_non_negative, y)\n","\n","# ## Data Augmentation Teknikleri\n","\n","# ### 1. SMOTE (Synthetic Minority Over-sampling Technique)\n","# Azınlık sınıfı (Okra) için sentetik örnekler oluştur\n","smote = SMOTE(random_state=50)\n","X_augmented, y_augmented = smote.fit_resample(X_non_negative, y)\n","\n","# ## Modelleri Oluşturma ve Doğruluk Oranlarını Karşılaştırma\n","\n","models = {\n"," #   'Decision Tree': DecisionTreeClassifier(),\n","    'Decision Tree': DecisionTreeClassifier(criterion='gini', max_depth=None,\n","                                    min_samples_split=3, min_samples_leaf=2,\n","                                    max_features=None),\n","   # 'Random Forest': RandomForestClassifier(),\n","    'Random Forest': RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None,\n","                                     min_samples_split=6, min_samples_leaf=5),\n","  #  'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=8),\n","    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=14, weights='uniform', algorithm='auto', leaf_size=30, p=4,\n","                                                metric='minkowski', metric_params=None, n_jobs=None),\n","    'Kompleks Support Vector Machine': SVC(kernel='sigmoid', C=10, gamma='scale')  # RBF kernel ve C=10\n","}\n","\n","# Farklı veri işleme kombinasyonları için doğruluk oranlarını hesapla\n","for model_name, model in models.items():\n","    for data_type, X_processed in [('Orijinal', X_non_negative), ('PCA', X_pca), ('Feature Selection', X_selected), ('SMOTE', X_augmented)]:\n","        X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","        dogruluk_orani = accuracy_score(y_test, y_pred)\n","        print(f\"{model_name} ({data_type}) Doğruluk Oranı: {dogruluk_orani:.4f}\")\n"],"id":"IWh8KxKSVb5-"},{"cell_type":"markdown","metadata":{"id":"OQgOPI7tkx5o"},"source":["# PNG ile eğitim"],"id":"OQgOPI7tkx5o"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":205602,"status":"ok","timestamp":1710873244410,"user":{"displayName":"ALİ BAKİ TÜRKÖZ","userId":"13381081740374735745"},"user_tz":-180},"id":"omJRJlO0u0r8","outputId":"b63efaab-8d6f-4c97-e2b7-ae878c74d128"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Decision Tree Doğruluk Oranı: 0.5962\n","Random Forest Doğruluk Oranı: 0.6346\n","K-Nearest Neighbors Doğruluk Oranı: 0.5769\n","Support Vector Machine Doğruluk Oranı: 0.6346\n"]}],"source":["import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","\n","# Google Drive API\n","from google.colab import drive\n","\n","# Drive bağlantısını oluştur\n","drive.mount('/content/gdrive')\n","\n","# Veri klasörlerini belirt\n","okra_klasoru = '/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Grafikler/130Data_40_228_BlackBox_Factory_Grafikler/Okralı'\n","normal_klasoru = '/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Grafikler/130Data_40_228_BlackBox_Factory_Grafikler/Normal'\n","\n","# Görüntüleri ve etiketleri depolamak için boş listeler oluştur\n","X = []  # Görüntüler\n","y = []  # Etiketler\n","\n","# Okralı verileri yükle\n","okra_dosyaları = os.listdir(okra_klasoru)\n","for dosya in okra_dosyaları:\n","    dosya_yolu = os.path.join(okra_klasoru, dosya)\n","    görüntü = cv2.imread(dosya_yolu)\n","    # Görüntüyü işleme ve özellik vektörüne dönüştürme\n","    özellik_vektörü = görüntü.flatten()  # Örnek olarak düz birleştirme (flatten)\n","    X.append(özellik_vektörü)\n","    y.append(1)  # Okra sınıfı etiketi\n","\n","# Normal verileri yükle\n","normal_dosyaları = os.listdir(normal_klasoru)\n","for dosya in normal_dosyaları:\n","    dosya_yolu = os.path.join(normal_klasoru, dosya)\n","    görüntü = cv2.imread(dosya_yolu)\n","    # Görüntüyü işleme ve özellik vektörüne dönüştürme\n","    özellik_vektörü = görüntü.flatten()  # Örnek olarak düz birleştirme (flatten)\n","    X.append(özellik_vektörü)\n","    y.append(0)  # Normal sınıfı etiketi\n","\n","# Verileri NumPy dizilerine dönüştürme\n","X = np.array(X)\n","y = np.array(y)\n","\n","# Verileri eğitim ve test setlerine ayır\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Modelleri oluştur\n","models = {\n","    'Decision Tree': DecisionTreeClassifier(),\n","    'Random Forest': RandomForestClassifier(),\n","    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n","    'Support Vector Machine': SVC(kernel='linear', C=10)\n","}\n","\n","# Modelleri eğit ve doğruluk oranlarını ekrana bastır\n","for model_name, model in models.items():\n","    # Veri normalizasyonu\n","    scaler = StandardScaler()\n","    X_train_scaled = scaler.fit_transform(X_train)\n","    X_test_scaled = scaler.transform(X_test)\n","\n","    # Modeli eğit\n","    model.fit(X_train_scaled, y_train)\n","\n","    # Modeli test et ve doğruluk oranını hesapla\n","    y_pred = model.predict(X_test_scaled)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(f\"{model_name} Doğruluk Oranı: {accuracy:.4f}\")\n","\n"],"id":"omJRJlO0u0r8"},{"cell_type":"code","execution_count":null,"metadata":{"id":"qfzJoyT_7iYT"},"outputs":[],"source":[],"id":"qfzJoyT_7iYT"},{"cell_type":"markdown","metadata":{"id":"XQgNVeVj89tD"},"source":["# PNG Feature Extract + Data Aug"],"id":"XQgNVeVj89tD"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvx4a-US9FBy","executionInfo":{"status":"ok","timestamp":1711108091777,"user_tz":-180,"elapsed":1471562,"user":{"displayName":"ALİ BAKİ TÜRKÖZ","userId":"13381081740374735745"}},"outputId":"ce7af13e-38a4-4855-f8c3-e601e08a5a56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","Decision Tree (Orijinal) Doğruluk Oranı: 0.6250\n","Decision Tree (PCA) Doğruluk Oranı: 0.6562\n","Decision Tree (Feature Selection) Doğruluk Oranı: 0.6875\n","Decision Tree (SMOTE) Doğruluk Oranı: 0.6406\n","Random Forest (Orijinal) Doğruluk Oranı: 0.7812\n","Random Forest (PCA) Doğruluk Oranı: 0.7656\n","Random Forest (Feature Selection) Doğruluk Oranı: 0.6875\n","Random Forest (SMOTE) Doğruluk Oranı: 0.7656\n","K-Nearest Neighbors (Orijinal) Doğruluk Oranı: 0.7656\n","K-Nearest Neighbors (PCA) Doğruluk Oranı: 0.7500\n","K-Nearest Neighbors (Feature Selection) Doğruluk Oranı: 0.7031\n","K-Nearest Neighbors (SMOTE) Doğruluk Oranı: 0.7656\n","Kompleks Support Vector Machine (Orijinal) Doğruluk Oranı: 0.7344\n","Kompleks Support Vector Machine (PCA) Doğruluk Oranı: 0.7188\n","Kompleks Support Vector Machine (Feature Selection) Doğruluk Oranı: 0.7031\n","Kompleks Support Vector Machine (SMOTE) Doğruluk Oranı: 0.7344\n"]}],"source":["import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.feature_selection import SelectKBest, chi2\n","from imblearn.over_sampling import SMOTE\n","\n","# Google Drive API\n","from google.colab import drive\n","\n","# Drive bağlantısını oluştur\n","drive.mount('/content/gdrive')\n","\n","# Veri klasörlerini belirt\n","okra_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Grafikler/160Data_20_352_White_Factory_Graphs/Okralı\"\n","normal_klasoru = \"/content/gdrive/MyDrive/AliBaki_TURKOZ_Engineering_Project/Data_Sets/Grafikler/160Data_20_352_White_Factory_Graphs/Normal\"\n","\n","# Görüntüleri ve etiketleri depolamak için boş listeler oluştur\n","X = []  # Görüntüler\n","y = []  # Etiketler\n","\n","# Okralı verileri yükle\n","okra_dosyaları = os.listdir(okra_klasoru)\n","for dosya in okra_dosyaları:\n","    dosya_yolu = os.path.join(okra_klasoru, dosya)\n","    görüntü = cv2.imread(dosya_yolu)\n","    # Görüntüyü işleme ve özellik vektörüne dönüştürme\n","    özellik_vektörü = görüntü.flatten()  # Örnek olarak düz birleştirme (flatten)\n","    X.append(özellik_vektörü)\n","    y.append(1)  # Okra sınıfı etiketi\n","\n","# Normal verileri yükle\n","normal_dosyaları = os.listdir(normal_klasoru)\n","for dosya in normal_dosyaları:\n","    dosya_yolu = os.path.join(normal_klasoru, dosya)\n","    görüntü = cv2.imread(dosya_yolu)\n","    # Görüntüyü işleme ve özellik vektörüne dönüştürme\n","    özellik_vektörü = görüntü.flatten()  # Örnek olarak düz birleştirme (flatten)\n","    X.append(özellik_vektörü)\n","    y.append(0)  # Normal sınıfı etiketi\n","\n","# Verileri NumPy dizilerine dönüştürme\n","X = np.array(X)\n","y = np.array(y)\n","\n","# Verileri eğitim ve test setlerine ayır\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# ## Feature Extraction Teknikleri\n","\n","# ### 1. Principal Component Analysis (PCA)\n","# 2 bileşene indirge\n","pca = PCA(n_components=2)\n","X_pca = pca.fit_transform(X)\n","\n","# ### 2. Feature Selection\n","# En iyi 2 özelliği seç\n","selector = SelectKBest(chi2, k=2)\n","X_selected = selector.fit_transform(X, y)\n","\n","# ## Data Augmentation Teknikleri\n","\n","# ### 1. SMOTE (Synthetic Minority Over-sampling Technique)\n","# Azınlık sınıfı (Okra) için sentetik örnekler oluştur\n","smote = SMOTE(random_state=50)\n","X_augmented, y_augmented = smote.fit_resample(X, y)\n","\n","# ## Modelleri Oluşturma ve Doğruluk Oranlarını Karşılaştırma\n","\n","models = {\n","   # 'Decision Tree': DecisionTreeClassifier(),\n","    'Decision Tree': DecisionTreeClassifier(criterion='gini', max_depth=None,\n","                                    min_samples_split=3, min_samples_leaf=2,\n","                                    max_features=None),\n","   # 'Random Forest': RandomForestClassifier(),\n","    'Random Forest': RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None,\n","                                     min_samples_split=6, min_samples_leaf=5),\n","   # 'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=8),\n","    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=8, weights='uniform', algorithm='auto', leaf_size=30, p=4,\n","                                                metric='minkowski', metric_params=None, n_jobs=None),\n","    'Kompleks Support Vector Machine': SVC(kernel='rbf', C=13, gamma='scale')  # RBF kernel ve C=10\n","}\n","\n","# Farklı veri işleme kombinasyonları için doğruluk oranlarını hesapla\n","for model_name, model in models.items():\n","    for data_type, X_processed in [('Orijinal', X), ('PCA', X_pca), ('Feature Selection', X_selected), ('SMOTE', X_augmented)]:\n","        X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","        dogruluk_orani = accuracy_score(y_test, y_pred)\n","        print(f\"{model_name} ({data_type}) Doğruluk Oranı: {dogruluk_orani:.4f}\")"],"id":"pvx4a-US9FBy"},{"cell_type":"code","execution_count":null,"metadata":{"id":"TkhKJbxPW3Lk"},"outputs":[],"source":[],"id":"TkhKJbxPW3Lk"},{"cell_type":"code","execution_count":null,"metadata":{"id":"_AbUJTMN9Rpu"},"outputs":[],"source":[],"id":"_AbUJTMN9Rpu"},{"cell_type":"code","execution_count":null,"metadata":{"id":"AbL2F3BGU0vx"},"outputs":[],"source":[],"id":"AbL2F3BGU0vx"}],"metadata":{"colab":{"collapsed_sections":["zoSHqiqRZVTF","0BYhuUoJkdg1","CQ4rrsB1kRuf","uXPxt2Hd47j6","W2uWJaIWMUTO","kq8MWAt5ajHo","OQgOPI7tkx5o"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}